--
title: "Introduction to slimmmingDive"
author: "Fer Arce"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```



This is a minimal example to introduce the usage of **slimmingDive**
with Southern elephant seals summarized dive information kindly
provided by the Australian Integrated Marine Observing System
(IMOS). It requires the external software JAGS (Just another Gibs
sampler) to be installed or slimmingDive will fail to install.

slimmingDive is not on cran, so you need to download and install it
locally. You can also use either `remotes` or `devtools` packages.

```{r }
## remotes::install_github('farcego/slimmingDive')

```

Load the package and the build-in data:

```{r }
library(slimmingDive)

data(ele)


```

These type of datasets tipically contain a large number of columns,
innecesary to our purposes, so better to pre-process the data and get
rid of them. This first step remove certain dives. First, it will
remove dives shallower than 100 m depth and 300 s of duration. These
are a minority of dives and it should not have an impact on drift
dives. It will sort the data by date (it should be already sorted),
andremove repeated rows (if any) and those with have certain errors
like more than one inflection point at the same time.

```{r }
Data <- formatDives(ele)

dim(Data)
```

Next step is to otain the order in which the inflection points were
generated onboard the tag, and the residual of the last point, as the
drifing segment and drift rate toguether plus furter calculations
depend on them.

```{r }

Data[c('order','minresid')] <- t(apply(Data,1,RBSM,retrieve='both'))
Data$minresid <- as.numeric(Data$minresid)
```

We can now generate the variables needed for the filtering process:

```{r }
D1 <- newVarsVect(Data)
```
And get the Drift rate estimate and drifting segment:

```{r }
D1[c('NDE','ds')] <- t(apply(D1,1,NDE, extract='both'))
```
We have a bunch of candidate drift dives with associated drift rates,
but most of them are non drift dives and will be rejected at the next
step:



```{r }
plotDrift(D1, xlab = 'foraging days', ylab = 'Drift rate',
         cex.lab = 1.5, cex = 2)
```

to get ride of those that are certainly non drift dives, we pass a
flexible filter based on the previously calculated variables:

```{r }
D1 <- driftFilter(D1)
```

And we can see again how the drifting trajectory looks like:

```{r }
plotDrift(D1, xlab = 'foraging days', ylab = 'Drift rate', cex.lab = 1.5, cex = 2)
```

A pattern aroses, but a last step is required to filter the
unrealistic values still retained by the filtering process. Because
it is time consuming, we can load the same seal but fully processed. The data
cames cames as a list:

```{r }

## if you want to run the kalman filter, uncomment the line below and run it.
## D2 <- kalman(D1,400000, 10000, n.adap = 10000)

data(elek)

## class(elek) <- append(class(elek), 'kalman')
```

```{r }
##load('../data/elek.RData')
D2 <- postKalman(elek)
## At this point, we need to set a zeta threshold (Z = probability of
## a given drift rate being in the drifting trajectory of the
## seal. Most of the case, any value above 0.5 will yield indeitcal or
## close to identical results, as the distribution oz Z is storngly
## bimodal towards either 0 or 1. If there is going to be some
## smoothiing afterwards, I would guess that any value above 0.5
## should yield practical identiocal fits
```
```{r }
D2 <- D2[D2$zetas > .5, ]
plotDrift(D2, xlab = 'foraging days',cex.lab = 1.5, cex = 2,
          ylab = 'Drift rate')
```

```{r }

## And now we make the gam



D3 <- makeTheGam(D2)





plotDrift(D2, xlab = 'foraging days',cex.lab = 1.5, cex = 2,
          ylab = 'Drift rate')
lapply(D3, function(fo){points(fo$Date, fo$pred, type = 'l', col = 'firebrick', lwd = 3)})

drift

help('help')

browseURL('drift')
```
